{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: elianapinto20@outlook.com\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "email = os.getenv('email')\n",
    "password = os.getenv('password')\n",
    "\n",
    "print(f\"Email: {email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias \n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignorar warnings de pandas sobre cambios futuros\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias Selenium\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By  # buscar por etiquetas, clases, ids, paths, xpaths\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Webscrapping data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagina_principal(url):\n",
    "    # agregar opciones al driver\n",
    "    options = Options()\n",
    "\n",
    "    # Ajustar el custom User-Agent, evitar bloqueos facilmente\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "    # Inicializar el webdriver con las opciones personalizadas. \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # maximizar pantalla\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # Entra a la pagina\n",
    "    driver.get(url)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in(driver):\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Espera explícita para el enlace de inicio de sesión\n",
    "        sign_in_link = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"signIn\"]/div/div/a'))\n",
    "        )\n",
    "        sign_in_link.click()\n",
    "\n",
    "        # Espera explícita para el botón de inicio de sesión\n",
    "        sign_in_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.gr-button.gr-button--dark.gr-button--auth.authPortalConnectButton.authPortalSignInButton'))\n",
    "        )\n",
    "        sign_in_button.click()\n",
    "\n",
    "        # Encuentra el campo de correo electrónico y envía el correo\n",
    "        email_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"ap_email\"))\n",
    "        )\n",
    "        email_input.send_keys(f\"{email}\")\n",
    "\n",
    "        # Encuentra el campo de contraseña y envía la contraseña\n",
    "        password_input = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"ap_password\"))\n",
    "        )\n",
    "        password_input.send_keys(f\"{password}\")\n",
    "\n",
    "        # Encuentra y haz clic en el botón de envío\n",
    "        sign_in_submit_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"signInSubmit\"))\n",
    "        )\n",
    "        sign_in_submit_button.click()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW ! \n",
    "# def iniciar_y_logear(driver, url):\n",
    "#     # Llamamos a la función para abrir la página\n",
    "#     driver = iniciar_driver(url)\n",
    "    \n",
    "#     # Llamamos a la función para iniciar sesión después de abrir la página\n",
    "#     sign_in(driver)\n",
    "\n",
    "# # Llamamos a la función que incluye ambas acciones\n",
    "# iniciar_y_logear(driver, 'http://example.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_all_genres(driver):\n",
    "    \n",
    "    # Espera hasta que el span con el texto \"Browse ▾\" sea clickeable\n",
    "    browse_span = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//span[text()='Browse ▾']\"))\n",
    "    )\n",
    "\n",
    "    # Haz clic en el span\n",
    "    browse_span.click()\n",
    "\n",
    "    # Espera hasta que el enlace \"All Genres\" sea clickeable\n",
    "    all_genres_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[text()='All Genres']\"))\n",
    "    )\n",
    "\n",
    "    # Haz clic en el enlace \"All Genres\"\n",
    "    all_genres_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict():\n",
    "    books_inf = {\n",
    "    'books': [],\n",
    "    'writer': [],\n",
    "    'rating': [],\n",
    "    'description': [],\n",
    "    'statistics': [],\n",
    "    'details': [],\n",
    "    'urls': [],\n",
    "    'gen': [],\n",
    "    'reading': [],\n",
    "    'will_read': [],\n",
    "    'isbn': [],\n",
    "    'ediciones': [],\n",
    "    'published': [],\n",
    "    'format': [],\n",
    "    'asin': [],\n",
    "    'language': []\n",
    "    }\n",
    "    return books_inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(driver):\n",
    "    try:\n",
    "        # Encuentra todos los nombres de géneros\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, \".bigBoxContent a.gr-hyperlink\")\n",
    "        names = [element.text for element in elements]\n",
    "    except TimeoutException:\n",
    "        logging.error(\"Error general: No se pudo cargar la lista de géneros (Timeout).\")\n",
    "    except NoSuchElementException:\n",
    "        logging.error(\"Error: No se encontraron los géneros en la página.\")\n",
    "    except WebDriverException as e:\n",
    "        logging.error(f\"Error del navegador\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inesperado: {e}\")\n",
    "\n",
    "    return names[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_books(driver, gen): \n",
    "    try:\n",
    "        # Ajuste de XPath: buscar el enlace basado en el texto dinámico \"More {gen} books...\"\n",
    "        gen_link = WebDriverWait(driver, 20).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, f'//a[@class=\"actionLink\" and contains(text(), \"More {gen} books\")]'))\n",
    "        )\n",
    "        \n",
    "        # Scroll hacia el enlace para asegurarse de que está visible\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", gen_link)\n",
    "        \n",
    "        # Hacer clic en el enlace\n",
    "        gen_link.click()\n",
    "        \n",
    "        logging.info(f\"Se hizo clic en 'More {gen} books...' para {gen}.\")\n",
    "    \n",
    "    except TimeoutException:\n",
    "        logging.error(f\"Timeout al intentar encontrar el enlace para '{gen}'. El enlace puede no estar visible.\")\n",
    "    except NoSuchElementException:\n",
    "        logging.error(f\"El enlace para '{gen}' no se encontró.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al intentar hacer clic en 'More {gen} books...' para {gen}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        ## AQUI VA UNA FUNCION QUE BUSCA LOS LIBROS Y LUEGO LOS REVISA Y SACA LA INFO \n",
    "        ## DEBO VOLVER ATRAS PORQUE TIENE VARIOS LINKS LA PAGINA O? \n",
    "\n",
    "\n",
    "        # # Regresar nuevamente a la página anterior\n",
    "        # driver.back()\n",
    "        # time.sleep(2)  # Pausa para permitir la carga de la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_a_genre(driver):\n",
    "\n",
    "    for gen in genres:\n",
    "        # Este rango parece estar limitado a 1 género, puedes ajustar el rango según sea necesario\n",
    "        logging.info(f\"Procesando género: {gen}\")\n",
    "        \n",
    "        try:\n",
    "            # Esperar que el enlace sea clickeable y hacer clic\n",
    "            art_link = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, f\"//a[contains(text(), '{gen}')]\"))\n",
    "            )\n",
    "            art_link.click()\n",
    "            time.sleep(1)  # Pausa para permitir la carga de la página\n",
    "            # Llamamos a go_to_all_genres después de procesar un género, si es necesario\n",
    "\n",
    "            explore_books(driver, gen)\n",
    "            go_to_all_genres(driver)\n",
    "            \n",
    "        except TimeoutException:\n",
    "            logging.error(f\"Error: No se pudo hacer clic en el enlace para '{gen}' (Timeout).\")\n",
    "        except NoSuchElementException:\n",
    "            logging.error(f\"Error: No se encontró el enlace para '{gen}'.\")\n",
    "        except WebDriverException as e:\n",
    "            logging.error(f\"Error del navegador: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(f\"Navegando a: {driver.current_url}\")\n",
    "\n",
    "# # Ahora buscar los enlaces en esta página\n",
    "# urls = get_links()\n",
    "# for url in urls:\n",
    "#     get_information(url, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(driver): \n",
    "\n",
    "    URLS = []\n",
    "    try: \n",
    "        logging.info(\"Proceeding with scraping book URLs...\")\n",
    "        anchor_tag = driver.find_elements(By.XPATH, \"//a[starts-with(@href, '/book/show')]\")\n",
    "    \n",
    "        # Iterate over anchor tags and collect URLs\n",
    "        for get_href in anchor_tag:\n",
    "            url = get_href.get_attribute('href')\n",
    "            URLS.append(url)\n",
    "            logging.info(f\"Found book URL: {url}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log error if no book URLs are found\n",
    "        logging.error(f\"Error occurred while trying to find book URLs\")\n",
    "    \n",
    "    return URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF79BC6FB05+28789]\n\t(No symbol) [0x00007FF79BBD86E0]\n\t(No symbol) [0x00007FF79BA7592A]\n\t(No symbol) [0x00007FF79BAC930E]\n\t(No symbol) [0x00007FF79BAC95FC]\n\t(No symbol) [0x00007FF79BB128A7]\n\t(No symbol) [0x00007FF79BAEF47F]\n\t(No symbol) [0x00007FF79BB0F654]\n\t(No symbol) [0x00007FF79BAEF1E3]\n\t(No symbol) [0x00007FF79BABA938]\n\t(No symbol) [0x00007FF79BABBAA1]\n\tGetHandleVerifier [0x00007FF79BFA933D+3410093]\n\tGetHandleVerifier [0x00007FF79BFBE7DD+3497293]\n\tGetHandleVerifier [0x00007FF79BFB2A73+3448803]\n\tGetHandleVerifier [0x00007FF79BD37BBB+848171]\n\t(No symbol) [0x00007FF79BBE3C3F]\n\t(No symbol) [0x00007FF79BBDF6E4]\n\t(No symbol) [0x00007FF79BBDF87D]\n\t(No symbol) [0x00007FF79BBCED49]\n\tBaseThreadInitThunk [0x00007FF8451D7374+20]\n\tRtlUserThreadStart [0x00007FF845C9CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m driver \u001b[38;5;241m=\u001b[39m pagina_principal(url)\n\u001b[0;32m      4\u001b[0m sign_in(driver)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mgo_to_all_genres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m dict_dataframe \u001b[38;5;241m=\u001b[39m create_dict()\n\u001b[0;32m      7\u001b[0m genres \u001b[38;5;241m=\u001b[39m get_genres(driver)\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mgo_to_all_genres\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgo_to_all_genres\u001b[39m(driver):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Espera hasta que el span con el texto \"Browse ▾\" sea clickeable\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     browse_span \u001b[38;5;241m=\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_to_be_clickable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//span[text()=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrowse ▾\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Haz clic en el span\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     browse_span\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\envs\\venv_project\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF79BC6FB05+28789]\n\t(No symbol) [0x00007FF79BBD86E0]\n\t(No symbol) [0x00007FF79BA7592A]\n\t(No symbol) [0x00007FF79BAC930E]\n\t(No symbol) [0x00007FF79BAC95FC]\n\t(No symbol) [0x00007FF79BB128A7]\n\t(No symbol) [0x00007FF79BAEF47F]\n\t(No symbol) [0x00007FF79BB0F654]\n\t(No symbol) [0x00007FF79BAEF1E3]\n\t(No symbol) [0x00007FF79BABA938]\n\t(No symbol) [0x00007FF79BABBAA1]\n\tGetHandleVerifier [0x00007FF79BFA933D+3410093]\n\tGetHandleVerifier [0x00007FF79BFBE7DD+3497293]\n\tGetHandleVerifier [0x00007FF79BFB2A73+3448803]\n\tGetHandleVerifier [0x00007FF79BD37BBB+848171]\n\t(No symbol) [0x00007FF79BBE3C3F]\n\t(No symbol) [0x00007FF79BBDF6E4]\n\t(No symbol) [0x00007FF79BBDF87D]\n\t(No symbol) [0x00007FF79BBCED49]\n\tBaseThreadInitThunk [0x00007FF8451D7374+20]\n\tRtlUserThreadStart [0x00007FF845C9CC91+33]\n"
     ]
    }
   ],
   "source": [
    "# pagina a scrapear\n",
    "url = \"https://www.goodreads.com\" \n",
    "driver = pagina_principal(url)\n",
    "sign_in(driver)\n",
    "go_to_all_genres(driver)\n",
    "dict_dataframe = create_dict()\n",
    "genres = get_genres(driver)\n",
    "select_a_genre(driver)\n",
    "# explore_books(driver, gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = get_genres(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.goodreads.com/book/show/199793433-ingrained'\n",
    "# driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # try:\n",
    "# #     # Espera a que el elemento esté presente en el DOM\n",
    "# #     element = WebDriverWait(driver, 10).until(\n",
    "# #         EC.presence_of_element_located((By.CLASS_NAME, \"SocialSignalCard__caption\"))\n",
    "# #     )\n",
    "# #     # Verifica si el subtítulo está dentro del contenedor\n",
    "# #     captions = element.find_element(By.CLASS_NAME, \"SocialSignalsSection__caption\")\n",
    "# #     texto = captions.text\n",
    "# #     books_inf['reading'].append(texto if texto else None)\n",
    "# # except (NoSuchElementException, TimeoutException) as e:\n",
    "# #     logging.error(f\"Error finding or clicking the button: {e}\")\n",
    "\n",
    "\n",
    "# # try:\n",
    "# #     element = WebDriverWait(driver, 20).until(\n",
    "# #         EC.presence_of_element_located((By.XPATH, \"//div[@data-testid='toReadSignal']\"))\n",
    "# #     )\n",
    "# #     # Verifica si el subtítulo está dentro del contenedor\n",
    "# #     caption = element.find_element(By.XPATH, \"//div[@data-testid='toReadSignal']\")\n",
    "# #     texto = caption.text\n",
    "# #     books_inf['will_read'].append(texto if texto else None)\n",
    "\n",
    "# # except (NoSuchElementException, TimeoutException) as e:\n",
    "# #     logging.error(f\"Error finding or clicking the button: {e}\")\n",
    "\n",
    "\n",
    "# # try:\n",
    "# #     # Use XPath to find the element by its text\n",
    "# #     element = WebDriverWait(driver, 20).until(\n",
    "# #         EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'Show all 6 editions')]\"))\n",
    "# #     )\n",
    "    \n",
    "# #     # Get the text inside the span element\n",
    "# #     texto = element.text\n",
    "# #     print(texto)  # Or append it to your desired list\n",
    "# #     books_inf['ediciones'].append(texto if texto else None)\n",
    "\n",
    "# # except (NoSuchElementException, TimeoutException) as e:\n",
    "# #     logging.error(f\"Error finding the text: {e}\")\n",
    "\n",
    "# try:\n",
    "#     # Find the \"Format\" text\n",
    "#     format_text = WebDriverWait(driver, 20).until(\n",
    "#         EC.presence_of_element_located((By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][1]//div[contains(@class, 'TruncatedContent__text')]\"))\n",
    "#     ).text\n",
    "\n",
    "#     # Find the \"Published\" text\n",
    "#     published_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][2]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "#     # Find the \"ISBN\" text\n",
    "#     isbn_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][3]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "#     # Find the \"ASIN\" text\n",
    "#     asin_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][4]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "#     # Find the \"Language\" text\n",
    "#     language_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][5]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "#     # Print the extracted texts (or store them in a dictionary)\n",
    "#     print(\"Format:\", format_text)\n",
    "#     print(\"Published:\", published_text)\n",
    "#     print(\"ISBN:\", isbn_text)\n",
    "#     print(\"ASIN:\", asin_text)\n",
    "#     print(\"Language:\", language_text)\n",
    "\n",
    "#     # Optionally, append them to your dictionary or list\n",
    "#     books_inf['format'].append(format_text if format_text else None)\n",
    "#     books_inf['published'].append(published_text if published_text else None)\n",
    "#     books_inf['isbn'].append(isbn_text if isbn_text else None)\n",
    "#     books_inf['asin'].append(asin_text if asin_text else None)\n",
    "#     books_inf['language'].append(language_text if language_text else None)\n",
    "\n",
    "# except (NoSuchElementException, TimeoutException) as e:\n",
    "#     logging.error(f\"Error extracting data: {e}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information(url, gen):\n",
    "\n",
    "    books_inf['gen'].append(gen)\n",
    "    books_inf['urls'].append(url)\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Processing URL: {url}\")  # Log the URL being processed\n",
    "\n",
    "        if url:\n",
    "            # Navigate to the book's page\n",
    "            driver.get(url)\n",
    "            # Extraer nombre del libro\n",
    "            try:\n",
    "                names_book = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h1.Text.Text__title1')))\n",
    "                name = names_book.text.strip()\n",
    "                books_inf['books'].append(name if name else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting book name from {url}: {e}\")\n",
    "\n",
    "            # Extraer autores\n",
    "            try:\n",
    "                autores = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'span.ContributorLink__name')))\n",
    "                name_writer = [autor.text.strip() for autor in autores if autor.text.strip()]\n",
    "                books_inf['writer'].append(name_writer if name_writer else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting authors from {url}: {e}\")\n",
    "\n",
    "            # Extraer rating\n",
    "            try:\n",
    "                ratings_num = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.RatingStatistics__rating')))\n",
    "                ratings_num_text = ratings_num.text.strip()\n",
    "                books_inf['rating'].append(ratings_num_text if ratings_num_text else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting rating from {url}: {e}\")\n",
    "\n",
    "            # Extraer descripción\n",
    "            try:\n",
    "                desc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.Formatted')))\n",
    "                description = desc.text.strip()\n",
    "                books_inf['description'].append(description if description else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting description from {url}: {e}\")\n",
    "\n",
    "            # Extraer estadísticas\n",
    "            try:\n",
    "                statics = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'RatingStatistics__meta')))\n",
    "                ratings_book_views = statics[0].get_attribute('aria-label').strip() if statics else None\n",
    "                books_inf['statistics'].append(ratings_book_views if ratings_book_views else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting statistics from {url}: {e}\")\n",
    "\n",
    "            # Extraer detalles adicionales\n",
    "            try:\n",
    "                detail = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.FeaturedDetails p')))\n",
    "                dets = [det.text.strip() for det in detail if det.text.strip()]\n",
    "                books_inf['details'].append(dets if dets else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting details from {url}: {e}\")\n",
    "\n",
    "\n",
    "            # Initialize WebDriverWait with a timeout of 20 seconds\n",
    "            wait = WebDriverWait(driver, 20)\n",
    "\n",
    "            # Esperar explícitamente a que el botón sea visible y luego hacer clic\n",
    "            try:\n",
    "                # Esperar explícitamente a que el botón sea clickeable y luego hacer clic\n",
    "                button = wait.until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'Button--inline') and contains(@aria-label, 'Book details and editions')]\"))\n",
    "                )\n",
    "                button.click()\n",
    "                logging.info(\"Botón de detalles encontrado y clickeado.\")\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error finding or clicking the button: {e}\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                # Espera a que el elemento esté presente en el DOM\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"SocialSignalCard__caption\"))\n",
    "                )\n",
    "                # Verifica si el subtítulo está dentro del contenedor\n",
    "                captions = element.find_element(By.CLASS_NAME, \"SocialSignalsSection__caption\")\n",
    "                texto = captions.text\n",
    "                books_inf['reading'].append(texto if texto else None)\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error finding or clicking the button: {e}\")\n",
    "\n",
    "\n",
    "            try:\n",
    "                element = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//div[@data-testid='toReadSignal']\"))\n",
    "                )\n",
    "                # Verifica si el subtítulo está dentro del contenedor\n",
    "                caption = element.find_element(By.XPATH, \"//div[@data-testid='toReadSignal']\")\n",
    "                texto = caption.text\n",
    "                books_inf['will_read'].append(texto if texto else None)\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error finding or clicking the button: {e}\")\n",
    "\n",
    "\n",
    "            # try:\n",
    "            #     # Buscar el elemento que contiene \"Show all\" independientemente del número de ediciones\n",
    "            #     element = WebDriverWait(driver, 20).until(\n",
    "            #         EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'Show all')]\"))\n",
    "            #     )\n",
    "                \n",
    "            #     # Obtener el texto del elemento encontrado\n",
    "            #     texto = element.text\n",
    "            #     if texto:\n",
    "            #         print(f\"Texto encontrado: {texto}\")  # Mostrar el texto en la consola\n",
    "            #         books_inf['ediciones'].append(texto)  # Añadir el texto a la lista\n",
    "            #     else:\n",
    "            #         logging.info(\"El elemento está presente pero no contiene texto.\")\n",
    "            #         books_inf['ediciones'].append(None)\n",
    "\n",
    "            # except TimeoutException:\n",
    "            #     logging.warning(\"El elemento 'Show all' no está presente en esta URL.\")\n",
    "            #     books_inf['ediciones'].append(None)  # Registrar que no había texto\n",
    "\n",
    "            # except NoSuchElementException as e:\n",
    "            #     logging.error(f\"Error al buscar el texto: {e}\")\n",
    "            #     books_inf['ediciones'].append(None)  # Registrar que no había texto\n",
    "\n",
    "            try:\n",
    "                # Find the \"Format\" text\n",
    "                format_text = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][1]//div[contains(@class, 'TruncatedContent__text')]\"))\n",
    "                ).text\n",
    "\n",
    "                # Find the \"Published\" text\n",
    "                published_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][2]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "                # Find the \"ISBN\" text\n",
    "                isbn_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][3]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "                # Find the \"ASIN\" text\n",
    "                asin_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][4]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "                # Find the \"Language\" text\n",
    "                language_text = driver.find_element(By.XPATH, \"//dl[@class='DescList']//div[contains(@class, 'DescListItem')][5]//div[contains(@class, 'TruncatedContent__text')]\").text\n",
    "\n",
    "                # Optionally, append them to your dictionary or list\n",
    "                books_inf['format'].append(format_text if format_text else None)\n",
    "                books_inf['published'].append(published_text if published_text else None)\n",
    "                books_inf['isbn'].append(isbn_text if isbn_text else None)\n",
    "                books_inf['asin'].append(asin_text if asin_text else None)\n",
    "                books_inf['language'].append(language_text if language_text else None)\n",
    "\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                logging.error(f\"Error extracting data: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred for URL {url}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen= 'Art'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.goodreads.com/book/show/199793433-ingrained'\n",
    "# get_information(url, 'art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal para navegar por las categorías y páginas\n",
    "def main():\n",
    "    try:\n",
    "        # Encuentra todos los nombres de géneros\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, \".bigBoxContent a.gr-hyperlink\")\n",
    "        names = [element.text for element in elements]\n",
    "        \n",
    "        # Selecciona un rango de géneros para iterar\n",
    "        for gen in names[5:12]:  # Este rango parece estar limitado a 1 género, puedes ajustar el rango según sea necesario\n",
    "            logging.info(f\"Procesando género: {gen}\")\n",
    "            \n",
    "            try:\n",
    "                # Esperar que el enlace sea clickeable y hacer clic\n",
    "                art_link = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, f\"//a[contains(text(), '{gen}')]\"))\n",
    "                )\n",
    "                art_link.click()\n",
    "                time.sleep(1)  # Pausa para permitir la carga de la página\n",
    "                \n",
    "                logging.info(f\"Navegando a: {driver.current_url}\")\n",
    "                \n",
    "                # Ahora buscar los enlaces en esta página\n",
    "                urls = get_links()\n",
    "                for url in urls:\n",
    "                    get_information(url, gen)\n",
    "\n",
    "            except TimeoutException:\n",
    "                logging.error(f\"Error: No se pudo hacer clic en el enlace para '{gen}' (Timeout).\")\n",
    "            except NoSuchElementException:\n",
    "                logging.error(f\"Error: No se encontró el enlace para '{gen}'.\")\n",
    "            except WebDriverException as e:\n",
    "                logging.error(f\"Error del navegador: {e}\")\n",
    "\n",
    "            \n",
    "            # logging.info(f\"Regresaste a: {driver.current_url}\")\n",
    "            \n",
    "            # Intentar hacer clic en el enlace \"More art books...\"\n",
    "            try:\n",
    "                art_link = WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.XPATH, f'//a[@class=\"actionLink\" and @href=\"/shelf/show/{gen}\"]'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", art_link)\n",
    "                driver.execute_script(\"arguments[0].click();\")\n",
    "                \n",
    "                logging.info(f\"Se hizo clic en 'More art books...' para {gen}.\")\n",
    "                \n",
    "                # Ahora buscar enlaces en esta página también\n",
    "                urls = get_links()\n",
    "                for url in urls:\n",
    "                    get_information(url, gen)\n",
    "\n",
    "                # # Regresar nuevamente a la página anterior\n",
    "                # driver.back()\n",
    "                # time.sleep(2)  # Pausa para permitir la carga de la página\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error al intentar hacer clic en 'More art books...' para {gen}: {e}\")\n",
    "\n",
    "\n",
    "            # Regresar a la página anterior\n",
    "            # url = '' \n",
    "            # driver.()\n",
    "            # time.sleep(2)  # Pausa para permitir la carga de la página\n",
    "            \n",
    "    except TimeoutException:\n",
    "        logging.error(\"Error general: No se pudo cargar la lista de géneros (Timeout).\")\n",
    "    except NoSuchElementException:\n",
    "        logging.error(\"Error: No se encontraron los géneros en la página.\")\n",
    "    except WebDriverException as e:\n",
    "        logging.error(f\"Error del navegador: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inesperado: {e}\")\n",
    "\n",
    "# Llamar a la función principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # driver.quit()  # Cerrar el navegador cuando termine el script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_inf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(books_inf['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     # Encuentra todos los nombres de los géneros\n",
    "#     elements = driver.find_elements(By.CSS_SELECTOR, \".bigBoxContent a.gr-hyperlink\")\n",
    "#     names = [element.text for element in elements]\n",
    "    \n",
    "#     for gen in names[5:6]:\n",
    "#         print(gen)\n",
    "        \n",
    "#         try:\n",
    "#             print(f\"Procesando: {gen}\")\n",
    "            \n",
    "#             # Esperar que el enlace sea clickeable y hacer clic\n",
    "#             art_link = WebDriverWait(driver, 10).until(\n",
    "#                 EC.element_to_be_clickable((By.XPATH, f\"//a[contains(text(), '{gen}')]\"))\n",
    "#             )\n",
    "#             time.sleep(1)  # Pausa manual antes de hacer clic (opcional)\n",
    "#             art_link.click()\n",
    "            \n",
    "#             # Opcional: Realizar alguna acción en la nueva página\n",
    "#             print(f\"Navegando a: {driver.current_url}\")\n",
    "#             time.sleep(2)  \n",
    "            \n",
    "#             # Configure logging\n",
    "#             logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "#             try:\n",
    "#                 # Try to find and click on the \"Art\" link\n",
    "#                 art_news = WebDriverWait(driver, 10).until(\n",
    "#                     EC.element_to_be_clickable((By.XPATH, '//*[@id=\"bodycontainer\"]/div[3]/div[1]/div[2]/div[2]/div[4]/div[2]/div/div[5]/a'))\n",
    "#                 )\n",
    "#                 art_news.click()\n",
    "\n",
    "#                 logging.info(\"No botton to click.\")\n",
    "#                 urls = get_links()\n",
    "#                 for url in urls: \n",
    "#                     get_information(url)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 # Log error if \"Art\" link is not clickable or doesn't exist\n",
    "#                 logging.error(f\"Error occurred while trying to click on 'Art_news' link\")\n",
    "                \n",
    "#                 urls = get_links()\n",
    "#                 for url in urls: \n",
    "#                     get_information(url)\n",
    "\n",
    "#                         # Go back to the previous page\n",
    "#             driver.back()\n",
    "#             time.sleep(2)  # Adding a small delay to prevent rapid page reloads\n",
    "#             logging.info(f\"Current URL after going back: {driver.current_url}\")\n",
    "#                 # details.append([None])\n",
    "#             try:\n",
    "#                 # Wait for the \"More art books...\" link to be visible and clickable\n",
    "#                 art_link = WebDriverWait(driver, 10).until(\n",
    "#                     EC.visibility_of_element_located((By.XPATH, f'//a[@class=\"actionLink\" and @href=\"/shelf/show/{gen}\"]'))\n",
    "#                 )\n",
    "#                 # Scroll the element into view (if necessary)\n",
    "#                 driver.execute_script(\"arguments[0].scrollIntoView();\", art_link)\n",
    "#                 # Click the link using JavaScript (in case regular click doesn't work)\n",
    "#                 driver.execute_script(\"arguments[0].click();\", art_link)\n",
    "\n",
    "#                 logging.info(\"Successfully clicked on 'More art books...' link.\")\n",
    "#                 # puede que falte darle scrioll tiene 100 paginas/ se puede solo esta!\n",
    "#                 urls = get_links()\n",
    "#                 for url in urls: \n",
    "#                     get_information(url)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Error occurred while trying to click on 'More art books...' link: {e}\")\n",
    "            \n",
    "#             # Regresar a la página anterior\n",
    "#             driver.back()\n",
    "#             time.sleep(2)  # Pausa para garantizar que la página anterior esté cargada\n",
    "#             # Verificar que regresaste a la página correcta (opcional)\n",
    "#             print(f\"Regresaste a: {driver.current_url}\")\n",
    "\n",
    "#         except TimeoutException:\n",
    "#             print(f\"Error: No se pudo hacer clic en el enlace para '{gen}' (Timeout).\")\n",
    "#         except NoSuchElementException:\n",
    "#             print(f\"Error: No se encontró el elemento para '{gen}'.\")\n",
    "#         except WebDriverException as e:\n",
    "#             print(f\"Error del navegador: {e}\")\n",
    "            \n",
    "# except TimeoutError:\n",
    "#     print(f\"Ocurrió un error general: {gen}\")\n",
    "\n",
    "# # finally:\n",
    "# #     # Cerrar el navegador\n",
    "# #     driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retry_get_url(url, retries=2):\n",
    "\n",
    "#     attempt = 0\n",
    "#     while attempt < retries:\n",
    "#         try:\n",
    "#             driver.get(url)\n",
    "#             return True\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error accessing {url}, attempt {attempt + 1}: {e}\")\n",
    "#             time.sleep(3)\n",
    "#             attempt += 1\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "try:\n",
    "    # Try to find and click on the \"Art\" link\n",
    "    art_news = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"bodycontainer\"]/div[3]/div[1]/div[2]/div[2]/div[4]/div[2]/div/div[5]/a'))\n",
    "    )\n",
    "    art_news.click()\n",
    "    logging.info(\"No botton to click.\")\n",
    "except Exception as e:\n",
    "    # Log error if \"Art\" link is not clickable or doesn't exist\n",
    "    logging.error(f\"Error occurred while trying to click on 'Art_news' link\")\n",
    "    get_links()\n",
    "    get_information(URLS)\n",
    "\n",
    "try:\n",
    "    # Wait for the \"More art books...\" link to be visible and clickable\n",
    "    art_link = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '//a[@class=\"actionLink\" and @href=\"/shelf/show/art\"]'))\n",
    "    )\n",
    "    # Scroll the element into view (if necessary)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", art_link)\n",
    "    # Click the link using JavaScript (in case regular click doesn't work)\n",
    "    driver.execute_script(\"arguments[0].click();\", art_link)\n",
    "    logging.info(\"Successfully clicked on 'More art books...' link.\")\n",
    "\n",
    "    # puede que falte darle scrioll tiene 100 paginas/ se puede solo esta!\n",
    "    get_links()\n",
    "    get_information(URLS)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error occurred while trying to click on 'More art books...' link: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the previous page\n",
    "driver.back()\n",
    "\n",
    "# Optionally, you can check the current URL to verify you're back\n",
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     # If the \"Art\" link isn't found, proceed to scrape URLs from books\n",
    "#     try:\n",
    "#         logging.info(\"Proceeding with scraping book URLs...\")\n",
    "#         anchor_tag = driver.find_elements(By.XPATH, \"//a[starts-with(@href, '/book/show')]\")\n",
    "        \n",
    "#         # Iterate over anchor tags and collect URLs\n",
    "#         for get_href in anchor_tag:\n",
    "#             url = get_href.get_attribute('href')\n",
    "#             urls.append(url)\n",
    "#             logging.info(f\"Found book URL: {url}\")\n",
    "        \n",
    "#             try:\n",
    "#                 logging.info(f\"Processing URL: {url}\")  # Log the URL being processed\n",
    "            \n",
    "#                 if url:\n",
    "#                     urls.append(url)\n",
    "\n",
    "#                     # Navigate to the book's page\n",
    "#                     driver.get(url)\n",
    "#                     button = driver.find_element(By.XPATH, \"//button[@aria-label='Book details and editions']\")\n",
    "#                     button.click()\n",
    "\n",
    "#                     # Try to extract book name\n",
    "#                     try:\n",
    "#                         names_book = driver.find_element(By.CSS_SELECTOR, 'h1.Text.Text__title1')\n",
    "#                         name = names_book.text.strip()\n",
    "#                         books.append(name if name else None)\n",
    "#                     except (NoSuchElementException, TimeoutException) as e:\n",
    "#                         logging.error(f\"Error extracting book name from {url}: {e}\")\n",
    "#                         books.append(None)\n",
    "\n",
    "#                     # Try to extract authors\n",
    "#                     try:\n",
    "#                         autores = driver.find_elements(By.CSS_SELECTOR, 'span.ContributorLink__name')\n",
    "#                         name_writer = [autor.text.strip() for autor in autores if autor.text.strip()]\n",
    "#                         writer.append(name_writer if name_writer else None)\n",
    "#                     except (NoSuchElementException, TimeoutException) as e:\n",
    "#                         logging.error(f\"Error extracting authors from {url}: {e}\")\n",
    "#                         writer.append(None)\n",
    "\n",
    "#                     # Try to extract book rating\n",
    "#                     try:\n",
    "#                         ratings_num = driver.find_element(By.CSS_SELECTOR, 'div.RatingStatistics__rating').text.strip()\n",
    "#                         rating.append(ratings_num if ratings_num else None)\n",
    "#                     except (NoSuchElementException, TimeoutException) as e:\n",
    "#                         logging.error(f\"Error extracting rating from {url}: {e}\")\n",
    "#                         rating.append(None)\n",
    "\n",
    "#                     # Try to extract book description\n",
    "#                     try:\n",
    "#                         desc = driver.find_element(By.CSS_SELECTOR, 'span.Formatted').text.strip()\n",
    "#                         description.append(desc if desc else None)\n",
    "#                     except (NoSuchElementException, TimeoutException) as e:\n",
    "#                         logging.error(f\"Error extracting description from {url}: {e}\")\n",
    "#                         description.append(None)\n",
    "\n",
    "#                     # Try to extract views and reviews statistics\n",
    "#                     try:\n",
    "#                         statics = driver.find_elements(By.CLASS_NAME, 'RatingStatistics__meta')\n",
    "#                         ratings_book_views = statics[0].get_attribute('aria-label').strip() if statics else None\n",
    "#                         statistics.append(ratings_book_views if ratings_book_views else None)\n",
    "#                     except (NoSuchElementException, TimeoutException) as e:\n",
    "#                         logging.error(f\"Error extracting statistics from {url}: {e}\")\n",
    "#                         statistics.append(None)\n",
    "\n",
    "#                     # Try to extract detailed information\n",
    "#                     try:\n",
    "#                         detail = driver.find_elements(By.CSS_SELECTOR, 'div.FeaturedDetails p')\n",
    "#                         dets = [det.text.strip() for det in detail if det.text.strip()]\n",
    "#                         details.append(dets if dets else [None])\n",
    "#                     except (NoSuchElementException, TimeoutException) as e:\n",
    "#                         logging.error(f\"Error extracting details from {url}: {e}\")\n",
    "#                         details.append([None])\n",
    "\n",
    "#             except NoSuchElementException as e:\n",
    "#                 logging.error(f\"Element not found at URL {url}: {e}\")\n",
    "#                 url_missing.append(url)\n",
    "\n",
    "#             finally:\n",
    "#                 # Go back to the previous page\n",
    "#                 driver.back()\n",
    "#                 time.sleep(2)  # Adding a small delay to prevent rapid page reloads\n",
    "#                 logging.info(f\"Current URL after going back: {driver.current_url}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         # Log error if no book URLs are found\n",
    "#         logging.error(f\"Error occurred while trying to find book URLs: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# # After scraping, log the collected data\n",
    "# logging.info(f\"Books: {books}\")\n",
    "# logging.info(f\"Writers: {writer}\")\n",
    "# logging.info(f\"Ratings: {rating}\")\n",
    "# logging.info(f\"Description: {description}\")\n",
    "# logging.info(f\"Statistics: {statistics}\")\n",
    "# logging.info(f\"Details: {details}\")\n",
    "# logging.info(f\"URLs missing: {url_missing}\")\n",
    "\n",
    "\n",
    "\n",
    "# # Print the collected data (for demonstration)\n",
    "# print(\"Books:\", books)\n",
    "# print(\"Writers:\", writer)\n",
    "# print(\"Ratings:\", rating)\n",
    "# print(\"Description:\", description)\n",
    "# print(\"Statistics:\", statistics)\n",
    "# print(\"Details:\", details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH, \"//button[@aria-label='Book details and editions']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui estan los links de los libros por genero de libro.\n",
    "element = driver.find_elements(By.CLASS_NAME, 'gr-hyperlink')\n",
    "element[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_gen = []\n",
    "num_books = [] # numero libros por categoria\n",
    "\n",
    "# Define a function to extract URLs from the page\n",
    "def extract_urls():\n",
    "    \"\"\"\n",
    "    Esta funcion extrae los urls de los generos que los libros que se encuentran por genero de los links de genero.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num = 0\n",
    "        # Find elements with the combined class using XPath\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, 'div.leftAlignedImage.bookBox div a')\n",
    "        \n",
    "        for element in elements:\n",
    "            time.sleep(0.01)\n",
    "            url = element.get_attribute('href')\n",
    "            if url not in url_gen:\n",
    "                url_gen.append(url)\n",
    "                num += 1 \n",
    "        num_books.append(num)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(\"No link found on the page.\")\n",
    "\n",
    "    \n",
    "\n",
    "for i in urls:\n",
    "    if i:  # Ensure the URL is valid before trying to process it\n",
    "        driver.get(i)\n",
    "        extract_urls()\n",
    "\n",
    "print(url_gen)  # Output the list of generated URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui estan los links de los libros por genero de libro.\n",
    "element = driver.find_elements(By.CLASS_NAME, 'gr-hyperlink')\n",
    "element[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimiento.**\n",
    "1. Primero se tomaran los links de los distintos generos de libros que hay en la pagina.\n",
    "2. Luego se iterara sobre esta lista de url con los generos para tomar los libros pertenecientes a cada clase.\n",
    "3. Se cuentas cuantos libro aparecen por genero.\n",
    "4. Con la lista de generos se itera sobre cada url para tomar los urls de los libros para cada genero.\n",
    "5. Para cada url de cada libro se itera y se extrae la siguiente informacion: \n",
    "> - Nombre del libro - titulo\n",
    "> - Autor o autores\n",
    "> - Calificacion\n",
    "> - Estadisticas, reviews y votos\n",
    "> - Descripcion \n",
    "> - Detalles, fecha e informacion del libro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Link por genero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar links de generos. \n",
    "urls = []\n",
    "\n",
    "for item in element:\n",
    "    try:\n",
    "        # URL\n",
    "        url = item.get_attribute('href')\n",
    "        urls.append(url)\n",
    "      \n",
    "    except:\n",
    "        NoSuchElementException\n",
    "\n",
    "urls = urls\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls por genero\n",
    "urls = urls[3:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan los links en un dataframe para pasarlos a un csv asi no estar recogiendo esta informacion cada vez que se ejecuta el programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda en un csv.\n",
    "dt = pd.DataFrame({\"url_gen\": urls,\n",
    "                  \"books_amount\": num_books})\n",
    "dt.to_csv('link_books.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer los los datos de links por genero.\n",
    "dt = pd.read_csv('link_genre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = dt['url_gen'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Link para cada libro por genero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_gen = []\n",
    "num_books = [] # numero libros por categoria\n",
    "\n",
    "# Define a function to extract URLs from the page\n",
    "def extract_urls():\n",
    "    \"\"\"\n",
    "    Esta funcion extrae los urls de los generos que los libros que se encuentran por genero de los links de genero.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num = 0\n",
    "        # Find elements with the combined class using XPath\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, 'div.leftAlignedImage.bookBox div a')\n",
    "        \n",
    "        for element in elements:\n",
    "            time.sleep(0.01)\n",
    "            url = element.get_attribute('href')\n",
    "            if url not in url_gen:\n",
    "                url_gen.append(url)\n",
    "                num += 1 \n",
    "        num_books.append(num)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(\"No link found on the page.\")\n",
    "\n",
    "    \n",
    "\n",
    "for i in urls:\n",
    "    if i:  # Ensure the URL is valid before trying to process it\n",
    "        driver.get(i)\n",
    "        extract_urls()\n",
    "\n",
    "print(url_gen)  # Output the list of generated URLs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente se guardan los links para cada libro por genero en un csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame({\"url_gen\": url_gen})\n",
    "dt.to_csv('link_books_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('link_books_all.csv')\n",
    "url_gen = dt.url_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 837 urls con libros\n",
    "len(url_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Assuming driver and url_gen are already defined\n",
    "url_missing = []\n",
    "fechas = []\n",
    "reviews = []\n",
    "\n",
    "for url in url_gen[0:2]:  # Loops through all URLs\n",
    "    print(f\"Processing URL: {url}\")\n",
    "    if url:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for the element containing the reviewer's name to be visible\n",
    "            wait = WebDriverWait(driver, 10)  # 10 seconds wait for elements\n",
    "            fecha_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.ReviewerProfile__name')))\n",
    "            \n",
    "            # Extract the text from each element\n",
    "            for fecha in fecha_elements:\n",
    "                fechas.append(fecha.text)\n",
    "            \n",
    "            print(f\"Extracted dates/review info: {fechas[-1]}\")  # Print last extracted item\n",
    "\n",
    "            # Wait for the element containing the reviewer's name to be visible\n",
    "            wait = WebDriverWait(driver, 10)  # 10 seconds wait for elements\n",
    "            reviewss = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div span.Formatted')))\n",
    "            \n",
    "            # Extract the text from each element\n",
    "            for fecha in reviewss:\n",
    "                reviews.append(fecha.text)\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Elemento no encontrado en la URL: {url}\")\n",
    "            url_missing.append(url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for URL {url}: {e}\")\n",
    "            url_missing.append(url)\n",
    "\n",
    "# Print out the missing URLs\n",
    "print(\"URLs with missing elements:\", url_missing)\n",
    "print(\"Extracted dates:\", fechas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fechas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extraccion de la Informacion de los libros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas con la informacion a extraer\n",
    "url_missing = []\n",
    "books = []\n",
    "writer = []\n",
    "rating = []\n",
    "statistics = []\n",
    "description = []\n",
    "details = []\n",
    "\n",
    "for url in url_gen[0:10]: \n",
    "    print(url)\n",
    "    if url:\n",
    "        name_writer = []\n",
    "        dets = []\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(0.01)\n",
    "\n",
    "            # driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[2]/main/div[1]/div[2]/div[2]/div[2]/div[7]/div/div/button/span[1]').click()\n",
    "\n",
    "            # Cod = driver.find_element(By.CSS_SELECTOR, 'div.EditionDetails')\n",
    "            # cod = cod.text\n",
    "            # print(cod)\n",
    "\n",
    "            \n",
    "            # Nombre libro\n",
    "            names_book = driver.find_element(By.CSS_SELECTOR, 'h1.Text.Text__title1')\n",
    "            name = names_book.text\n",
    "            books.append(name)\n",
    "\n",
    "            # autores \n",
    "            autores = driver.find_elements(By.CSS_SELECTOR, 'span.ContributorLink__name')\n",
    "            for i in autores:\n",
    "                autor = i.text\n",
    "                name_writer.append(autor)\n",
    "            writer.append(name_writer)\n",
    "\n",
    "            # Calificacion libro\n",
    "            ratings_num = driver.find_element(By.CSS_SELECTOR, 'div.RatingStatistics__rating').text\n",
    "            rating.append(ratings_num)\n",
    "\n",
    "            #description\n",
    "            desc = driver.find_element(By.CSS_SELECTOR, 'span.Formatted').text\n",
    "            description.append(desc)\n",
    "\n",
    "            # Views y reviews\n",
    "            statics = driver.find_elements(By.CLASS_NAME, 'RatingStatistics__meta')\n",
    "            ratings_book_views = statics[0].get_attribute('aria-label')\n",
    "            statistics.append(ratings_book_views)\n",
    "\n",
    "            # Extract the details\n",
    "            detail = driver.find_elements(By.CSS_SELECTOR, 'div.FeaturedDetails p')\n",
    "            for i in detail:\n",
    "                det = i.text\n",
    "                # Verificar si el texto no está vacío antes de agregarlo a la lista\n",
    "                if det.strip():  # .strip() elimina los espacios en blanco al principio y al final\n",
    "                    dets.append(det)\n",
    "            details.append(dets)\n",
    "\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            print(f\"Elemento no encontrado en la URL: {url}\")\n",
    "            url_missing.append(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Libros que no se encontro informacion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan los links de los libros que no se encuentras estos se pueden buscar especificamente por nombre y tomar la informacion de alli.  \n",
    "El programa leyó todos los links y obtuvo la informacion de todos los libros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los libros que no se cargan.\n",
    "url_missing\n",
    "\n",
    "for i, value in enumerate(url_gen):\n",
    "    if url_gen[i] == url_missing:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_url_book(url : str) -> str:\n",
    "    \"\"\"\n",
    "    Esta funcion recibe un string en formato url y extrae el nombre del libro y devuelve un string con el nombre del libro.\n",
    "\n",
    "    Arguments: \n",
    "        url: str\n",
    "\n",
    "    Return \n",
    "        str\n",
    "    \n",
    "    example:\n",
    "        >>>url = 'https://www.goodreads.com/book/show/30118.A_Light_in_the_Attic'\n",
    "        >>>name_url_book(url)\n",
    "        'A Light in the Attic'\n",
    "    \"\"\"\n",
    "\n",
    "    name = url.split('/')[-1]\n",
    "    if \"-\" in name:\n",
    "        name = \" \".join(name.split('-')[1:]).replace(\"-\", \" \")\n",
    "    elif '.' in name:\n",
    "        name = \" \".join(name.split('.')[1:]).replace(\"_\", \" \")\n",
    "\n",
    "    return name\n",
    "\n",
    "name_url_book(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar codigo\n",
    "url_missing = ['https://www.goodreads.com/book/show/30118.A_Light_in_the_Attic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar opciones al driver\n",
    "options = Options()\n",
    "\n",
    "# Ajustar el custom User-Agent, evitar bloqueos facilmente\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "# Inicializar el webdriver con las opciones personalizadas. \n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Maximizar la ventana\n",
    "driver.maximize_window()\n",
    "\n",
    "# pagina a scrapear\n",
    "url = \"https://www.goodreads.com/search?utf8=%E2%9C%93&query=\" \n",
    "\n",
    "# Entra a la pagina\n",
    "driver.get(url)\n",
    "\n",
    "for i in url_missing:\n",
    "\n",
    "    # buscar el boton de busqueda\n",
    "    book = driver.find_element(By.CSS_SELECTOR, \"input.searchBox__input.searchBox--large__input\")\n",
    "    book.click()\n",
    "\n",
    "    # nombre del libro a buscar\n",
    "    libro = name_url_book(i)\n",
    "    print(libro)\n",
    "\n",
    "    # Escribir el nombre del libro en el campo de búsqueda\n",
    "    book.send_keys(libro, Keys.ENTER)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "    # link = driver.find_element(By.XPATH, \"//a[contains(@href, 'book')]\")\n",
    "\n",
    "    # link = driver.find_element(By.XPATH, \"//a[contains(@href, 'book')]\")\n",
    "    # link.click\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Espera hasta 10 segundos para que el botón de cierre sea visible y luego haz clic en él\n",
    "        close_ad_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/div[3]/div/div/div[1]/button/img'))\n",
    "        )\n",
    "        close_ad_button.click()\n",
    "    except:\n",
    "        print(\"No se encontró el botón de cierre de la publicidad o no fue clickeable.\")\n",
    "\n",
    "\n",
    "    link = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.XPATH, \"//a[contains(@href, 'book')]\"))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# agregar opciones al driver\n",
    "options = Options()\n",
    "\n",
    "# Ajustar el custom User-Agent, evitar bloqueos facilmente\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\")\n",
    "\n",
    "# Inicializar el webdriver con las opciones personalizadas. \n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Maximizar la ventana\n",
    "driver.maximize_window()\n",
    "\n",
    "# pagina a scrapear\n",
    "url = \"https://www.goodreads.com/search?utf8=%E2%9C%93&query=\" \n",
    "\n",
    "# URL de la página inicial\n",
    "driver.get(url)\n",
    "\n",
    "# Iterar sobre la lista de libros\n",
    "for i in url_missing:\n",
    "    # Buscar el campo de búsqueda\n",
    "    book = driver.find_element(By.CSS_SELECTOR, \"input.searchBox__input.searchBox--large__input\")\n",
    "    \n",
    "    # Hacer clic en el campo de búsqueda\n",
    "    book.click()\n",
    "\n",
    "    # Obtener el nombre del libro a buscar\n",
    "    libro = name_url_book(i)\n",
    "    print(libro)\n",
    "\n",
    "    # Escribir el nombre del libro en el campo de búsqueda\n",
    "    book.send_keys(libro, Keys.ENTER)\n",
    "\n",
    "    # Manejar la publicidad (si aparece)\n",
    "    try:\n",
    "        # Esperar hasta que el botón de cierre de la publicidad sea clickeable\n",
    "        close_ad_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/div[3]/div/div/div[1]/button/img'))\n",
    "        )\n",
    "        close_ad_button.click()\n",
    "    except:\n",
    "        print(\"No se encontró el botón de cierre de la publicidad o no fue clickeable.\")\n",
    "    \n",
    "    # Esperar a que el enlace del libro sea visible antes de hacer clic\n",
    "    try:\n",
    "        link = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//a[contains(@href, '/book/show')]\"))\n",
    "        )\n",
    "        link.click()  # Hacer clic en el enlace del libro\n",
    "        # Esperar que la página del libro cargue completamente\n",
    "        print(f\"Accedió a la página del libro: {libro}\")\n",
    "    except:\n",
    "        print(f\"No se encontró el enlace para el libro: {libro}\")\n",
    "\n",
    "    # Pausa para evitar sobrecargar el servidor (puedes ajustarlo o eliminarlo si lo prefieres)\n",
    "    time.sleep(5)\n",
    "\n",
    "# Cerrar el navegador después de terminar\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.goodreads.com/blog/show/2842-readers-most-anticipated-books-of-2025?ref=BigBooks25_eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Informacion libros, creacion de dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books)\n",
    "len(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(writer)\n",
    "len(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rating)\n",
    "len(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics)\n",
    "len(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description)\n",
    "len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(details)\n",
    "len(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_gen[600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Book_name': books,\n",
    "        'writers': writer,\n",
    "        'rating': rating,\n",
    "        'statistics': statistics,\n",
    "        'description': description,\n",
    "        'url': url_gen[600:],\n",
    "        'details': details}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('df_books0_837.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer 300 libros el programa toma aproximadamente 25 minutos. Se guardan 3 como archivos separados por coma con 300, 299, y 237 datos. Se utlizaran estos datos para no estar cargando la pagina cada vez que se ejecute el notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Leer Datos, csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('df_books0_300.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('df_books0_599.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('df_books0_837.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Limpieza Datos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay columnas con datos en listas, como es el caso de la columna writers que son los autores del libro. Estos datos se cambian a tipo string para ingresarlos a la base de datos. Hay valores ademas repetidos en estas listas que tambien se remueven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['writers'] = df_total['writers'].map(lambda x: (\", \".join(set(writer.strip() for writer in x.strip().replace(\"[\", \"\").replace(']', \"\").split(\",\"))).replace(\"'\",'')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna statistics tiene dos valores que pueden ser valiosos para el analisis. La cantidad de las personas que califican el libro y la cantidad de reviews que recibe el libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_total[\"statistics\"]:\n",
    "    ratings, reviews = i.split('and')\n",
    "\n",
    "\n",
    "df_total['num_ratings'] = df_total['statistics'].map(lambda x: x.split('and')[0].split(\" \")[0])\n",
    "\n",
    "\n",
    "df_total['num_reviews'] = df_total['statistics'].map(lambda x: x.split('and')[1].split(\" \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.drop(['statistics'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['info_book'] = df_total['details'].map(lambda x: x.replace('[','').replace(']','').split(\",\")[0:2])\n",
    "df_total[\"publicacion\"] = df_total['details'].map(lambda x: x.replace('[','').replace(']','').split(\",\")[2:] if len(x.replace('[','').replace(']','').split(\",\")) > 2 else 'Falta info')\n",
    "# join(set(writer.strip() for writer in x.strip().replace(\"[\", \"\").replace(']', \"\").split(\",\"))).replace(\"'\",'')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['info_book'] = df_total['info_book'].map(lambda x: (\",\".join(x)).replace(\"'\",\"\"))\n",
    "df_total['publicacion'] = df_total['publicacion'].map(lambda x: (\",\".join(x)).replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.drop(['details'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['description'] = df_total['description'].map(lambda x: x.strip() if pd.notnull(x) else 'nocontent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los datos que se limpiaron se hace una copia. Luego se procede a guardar los datos en una base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(\"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para crear separar los autores que estan en una sola fila. Y asi crear mas tablas. \n",
    "#  def add_rows(df, name_column):\n",
    "\n",
    "#     \"\"\" \n",
    "#     Esta funcion crea columnas con 2 valores en una columna.\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Crear un nuevo DataFrame para almacenar las filas separadas\n",
    "#     new_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "#     # Iterar sobre cada fila del DataFrame original\n",
    "#     for index, row in df.iterrows():\n",
    "#         authors = row['writers'].split(', ')  # Separar los autores usando la coma como delimitador\n",
    "        \n",
    "#         # Crear una nueva fila para cada autor y agregarla al nuevo DataFrame\n",
    "#         for author in authors:\n",
    "#             new_row = row.copy()  # Copiar la fila original\n",
    "#             new_row['writers'] = author  # Reemplazar la columna 'writers' con un solo autor\n",
    "#             new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "#     # Mostrar el DataFrame resultante\n",
    "#     return new_df\n",
    "\n",
    "# add_rows(df_total, 'writers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Insertar datos en la base de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mysql\n",
    "# pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = mysql.connector.connect(user = \"root\", password = \"123mysequel\", host = \"127.0.0.1\", port =3308)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE BOOKS;\")\n",
    "cursor.execute(\"USE BOOKS;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to create the table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS books_db (\n",
    "    id_book INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(150),\n",
    "    rating FLOAT(3,2),\n",
    "    statistics VARCHAR(100),\n",
    "    description TEXT,\n",
    "    year INT,\n",
    "    information VARCHAR(250),\n",
    "    num_rating INT,\n",
    "    num_reviews INT,\n",
    "    url VARCHAR(200)\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query\n",
    "cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = \"\"\"\n",
    "ALTER TABLE books_db MODIFY COLUMN year VARCHAR(50);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query\n",
    "cursor.execute(create_table_query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"DESCRIBE books_db;\")\n",
    "result = cursor.fetchall()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear una lista con todos los datos a insertar\n",
    "data = []\n",
    "for _, row in df_total.iterrows():\n",
    "    name = row['Book_name']\n",
    "    rating = row['rating']\n",
    "    year = row['year_pub']\n",
    "    information = row['information']\n",
    "    num_rating = row['num_ratings']\n",
    "    num_reviews = row['num_reviews']\n",
    "    url = row['url']\n",
    "    description = row['description']\n",
    "\n",
    "    # Agregar cada fila como una tupla a la lista 'data'\n",
    "    data.append((name, rating, year, information, num_rating, num_reviews, url, description))\n",
    "\n",
    "# Ejecutar la inserción masiva utilizando executemany()\n",
    "add_producto = \"\"\"\n",
    "    INSERT INTO books_db \n",
    "    (name, rating, year, information, num_rating, num_reviews, url, description) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "cursor.executemany(add_producto, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar commit\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM books_db;\")\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Graficas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=df_total['rating']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
